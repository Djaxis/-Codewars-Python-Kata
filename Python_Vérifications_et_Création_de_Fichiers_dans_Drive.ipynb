{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODp1cH+vd4rIor6d3zsOf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Djaxis/MY-Python-Evolution/blob/main/Python_V%C3%A9rifications_et_Cr%C3%A9ation_de_Fichiers_dans_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Le but est de mettre en place un environnement pour recevoir de la data scrap de youtube pour du sentiment analysis\n"
      ],
      "metadata": {
        "id": "hJGBNQxZgOpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tiqzia2fyqg",
        "outputId": "186baad8-06c9-465a-f49c-4a2783417a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voici le contenu du dossier BDD dans votre Google Drive\n",
            "ls: cannot access '/content/drive/MyDrive/BDD/': No such file or directory\n",
            "Mounted at /content/drive\n",
            "Le dossier BDD EXISTE dans votre Google Drive\n",
            "Le dossier SCRAPPINGBDD EXISTE dans votre Google Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "print(\"Voici le contenu du dossier BDD dans votre Google Drive\")\n",
        "!ls /content/drive/MyDrive/BDD/\n",
        "\n",
        "# Chemin vers le driver\n",
        "driver_path = \"./chromedriver\"\n",
        "\n",
        "# monter votre Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# vérifier si le dossier 'BDD' existe dans votre Google Drive\n",
        "bdd_path = '/content/drive/MyDrive/BDD'\n",
        "if os.path.exists(bdd_path):\n",
        "    print(\"Le dossier BDD EXISTE dans votre Google Drive\")\n",
        "else:\n",
        "    os.mkdir(bdd_path)\n",
        "    print(\"Le dossier BDD n'existe PAS dans votre Google Drive\")\n",
        "\n",
        "# vérifier si le dossier 'SCRAPPINGBDD' existe dans votre Google Drive\n",
        "bdd_path = '/content/drive/MyDrive/BDD/SCRAPPINGBDD'\n",
        "if os.path.exists(bdd_path):\n",
        "    print(\"Le dossier SCRAPPINGBDD EXISTE dans votre Google Drive\")\n",
        "else:\n",
        "    os.mkdir(bdd_path)\n",
        "    print(\"Le dossier BDD n'existe PAS il donc créé dans votre Google Drive\")\n",
        "\n",
        "# vérifier si le fichier 'scrapyoutube2023.csv' existe dans le dossier 'BDD/SCRAPPINGBDD' de votre Google Drive\n",
        "csv_path = '/content/drive/MyDrive/BDD/SCRAPPINGBDD/scrapyoutube2023.csv'\n",
        "\n",
        "# si le fichier n'existe pas, créer un nouveau dataframe avec le nom \"scrapyoutube2023\"\n",
        "if not os.path.exists(csv_path):\n",
        "    scrapyoutube2023 = pd.DataFrame()\n",
        "    \n",
        "    # enregistrer le dataframe dans le fichier CSV\n",
        "    scrapyoutube2023.to_csv(csv_path, index=False)\n",
        "    print(f'Le fichier {csv_path} a été créé.')"
      ]
    }
  ]
}